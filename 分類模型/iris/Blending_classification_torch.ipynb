{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.Linear(20, 30, ac)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定義 smish 函數\n",
    "def smish(x):\n",
    "    return x * torch.tanh(torch.log(1 + torch.sigmoid(x)))\n",
    "\n",
    "class GatedLinearUnit(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super(GatedLinearUnit, self).__init__()\n",
    "        self.linear = nn.Linear(units)\n",
    "        self.sigmoid = nn.Sequential(nn.Linear(units), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.relu_dense = nn.Sequential(nn.Linear(units), smish())\n",
    "        self.linear_dense = nn.Linear(units)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.gated_linear_unit = GatedLinearUnit(units)\n",
    "        self.layer_norm = nn.LayerNorm()\n",
    "        self.project = nn.Linear(units)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu_dense(inputs)\n",
    "        x = self.linear_dense(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.project(inputs)\n",
    "        x = inputs + self.gated_linear_unit(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class VariableSelection(nn.Module):\n",
    "    def __init__(self, num_features, units, dropout_rate):\n",
    "        super(VariableSelection, self).__init__()\n",
    "        self.grns = nn.ModuleList()\n",
    "        # Create a GRN for each feature independently\n",
    "        for idx in range(num_features):\n",
    "            grn = GatedResidualNetwork(units, dropout_rate)\n",
    "            self.grns.append(grn)\n",
    "        # Create a GRN for the concatenation of all the features\n",
    "        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n",
    "        self.softmax = nn.Sequential(nn.Linear(units), nn.Softmax())\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        v = torch.cat(inputs, dim=-1)\n",
    "        v = self.grn_concat(v)\n",
    "        v = F.softmax(v, dim=-1)\n",
    "\n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = torch.stack(x, dim=1)\n",
    "\n",
    "        outputs = torch.squeeze(torch.matmul(v.unsqueeze(2), x), dim=2)\n",
    "        #torch.squeeze(torch.bmm(v.unsqueeze(2), x), dim=2)\n",
    "        return outputs\n",
    "\n",
    "class VariableSelectionFlow(nn.Module):\n",
    "    def __init__(self, num_features, units, dropout_rate, dense_units=None):\n",
    "        super(VariableSelectionFlow, self).__init__()\n",
    "        self.variableselection = VariableSelection(num_features, units, dropout_rate)\n",
    "        self.num_features = num_features\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_units = dense_units\n",
    "        if dense_units:\n",
    "            self.dense_list = nn.ModuleList([\n",
    "                nn.Linear(dense_units, dense_units) for _ in range(num_features)\n",
    "            ])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        split_input = torch.chunk(inputs, self.num_features, dim=-1)\n",
    "        if self.dense_units:\n",
    "            l = [self.dense_list[i](split_input[i]) for i in range(self.num_features)]\n",
    "        else:\n",
    "            l = split_input\n",
    "        return self.variableselection(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(data.drop(columns=['target'], axis=1), data[['target']], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/envs/tabpfn/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______fold 1______, ________repeat 1__________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m______fold \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m______, ________repeat \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m__________\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     model \u001b[39m=\u001b[39m CustomModel(units_1, drop_1, units_2, drop_2, units_3, drop_3, dense_units)\n\u001b[1;32m     50\u001b[0m     optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m)\n\u001b[1;32m     51\u001b[0m     loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mCustomModel.__init__\u001b[0;34m(self, units_1, drop_1, units_2, drop_2, units_3, drop_3, dense_units)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, units_1, drop_1, units_2, drop_2, units_3, drop_3, dense_units):\n\u001b[1;32m     15\u001b[0m     \u001b[39msuper\u001b[39m(CustomModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_1 \u001b[39m=\u001b[39m VariableSelectionFlow(\u001b[39m4\u001b[39;49m, units_1, drop_1, dense_units\u001b[39m=\u001b[39;49mdense_units)\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_2 \u001b[39m=\u001b[39m VariableSelectionFlow(units_1, units_2, drop_2)\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_3 \u001b[39m=\u001b[39m VariableSelectionFlow(units_2, units_3, drop_3)\n",
      "Cell \u001b[0;32mIn[7], line 73\u001b[0m, in \u001b[0;36mVariableSelectionFlow.__init__\u001b[0;34m(self, num_features, units, dropout_rate, dense_units)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_features, units, dropout_rate, dense_units\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     72\u001b[0m     \u001b[39msuper\u001b[39m(VariableSelectionFlow, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariableselection \u001b[39m=\u001b[39m VariableSelection(num_features, units, dropout_rate)\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features \u001b[39m=\u001b[39m num_features\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m units\n",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m, in \u001b[0;36mVariableSelection.__init__\u001b[0;34m(self, num_features, units, dropout_rate)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Create a GRN for each feature independently\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_features):\n\u001b[0;32m---> 46\u001b[0m     grn \u001b[39m=\u001b[39m GatedResidualNetwork(units, dropout_rate)\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrns\u001b[39m.\u001b[39mappend(grn)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Create a GRN for the concatenation of all the features\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mGatedResidualNetwork.__init__\u001b[0;34m(self, units, dropout_rate)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m units\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_rate \u001b[39m=\u001b[39m dropout_rate\n\u001b[0;32m---> 23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu_dense \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(nn\u001b[39m.\u001b[39;49mLinear(units), smish())\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_dense \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(units)\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(dropout_rate)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'out_features'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 定義自定義的 VariableSelectionFlow 層（已經在前面的回答中定義）\n",
    "# ... 請在這裡添加前面的 VariableSelectionFlow 定義 ...\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, units_1, drop_1, units_2, drop_2, units_3, drop_3, dense_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features_1 = VariableSelectionFlow(4, units_1, drop_1, dense_units=dense_units)\n",
    "        self.features_2 = VariableSelectionFlow(units_1, units_2, drop_2)\n",
    "        self.features_3 = VariableSelectionFlow(units_2, units_3, drop_3)\n",
    "        self.dense = nn.Linear(units_3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.features_1(x)\n",
    "        x = self.features_2(x)\n",
    "        x = self.features_3(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "batch_size = 32\n",
    "units_1 = 32\n",
    "drop_1 = 0.75\n",
    "dense_units = 8\n",
    "units_2 = 16\n",
    "drop_2 = 0.5\n",
    "units_3 = 8\n",
    "drop_3 = 0.25\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=722)\n",
    "X = torch.tensor(trainX.values, dtype=torch.float32)\n",
    "y_enc = LabelEncoder().fit_transform(trainy)\n",
    "y_label = torch.tensor(np.eye(3)[y_enc], dtype=torch.float32)\n",
    "blls = []\n",
    "\n",
    "for n, (train_idx, val_idx) in enumerate(cv.split(trainX, trainy)):\n",
    "    for k in range(3):\n",
    "        print(f'______fold {n+1}______, ________repeat {k+1}__________')\n",
    "        \n",
    "        model = CustomModel(units_1, drop_1, units_2, drop_2, units_3, drop_3, dense_units)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3, eps=1e-7)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1, verbose=True)\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', patience=25, verbose=False)\n",
    "        \n",
    "        train_data = TensorDataset(X[train_idx], y_label[train_idx])\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_data = TensorDataset(X[val_idx], y_label[val_idx])\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "        for epoch in range(20):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, torch.argmax(labels, dim=1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss = loss_fn(outputs, torch.argmax(labels, dim=1))\n",
    "                    val_losses.append(val_loss.item())\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            lr_scheduler.step(avg_val_loss)\n",
    "            print(f'Epoch [{epoch+1}/20], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        bll = nn.CrossEntropyLoss()(model(X[val_idx]), torch.argmax(y_label[val_idx], dim=1))\n",
    "        blls.append(bll)\n",
    "        print(f'BLL: {bll:.4f}')\n",
    "\n",
    "        torch.save(model.state_dict(), f'models_weights/mod_f{n}_r{k}.pth')\n",
    "\n",
    "print(np.mean(blls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n",
      "torch.Size([32, 4])\n",
      "torch.Size([25, 4])\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_loader:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorDataset' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data\u001b[39m.\u001b[39;49mto_numpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "train_data.to_numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
