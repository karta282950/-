{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_california_housing(as_frame=True)[\"frame\"]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(df.drop(columns=['MedHouseVal']), df.MedHouseVal, test_size=0.15, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "class Splitter:\n",
    "    def __init__(self, kfold=True, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.kfold = kfold\n",
    "        #self.greeks = greeks\n",
    "\n",
    "    def split_data(self, X, y, random_state_list):\n",
    "        if self.kfold == 'skf':\n",
    "            for random_state in random_state_list:\n",
    "                kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n",
    "                for train_index, val_index in kf.split(X, y):\n",
    "                    if type(X) is np.ndarray:\n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "                    else:\n",
    "                        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                    yield X_train, X_val, y_train, y_val\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid kfold: Must be True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, n_estimators=100, device=\"cpu\", random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.device = device\n",
    "        self.random_state = random_state\n",
    "        self.models = self._define_model()\n",
    "        self.models_name = list(self._define_model().keys())\n",
    "        self.len_models = len(self.models)\n",
    "        \n",
    "    def _define_model(self):\n",
    "        xgb_params = {}\n",
    "        param = {'n_estimators': 850, 'max_depth': 7, 'learning_rate': 0.035579334505517195, \n",
    "         'subsample': 0.7433060185168757, 'colsample_bytree': 0.9985782631581257, 'gamma': 0.014679853880810986}\n",
    "\n",
    "        if self.device == 'gpu':\n",
    "            xgb_params['tree_method'] = 'gpu_hist'\n",
    "            xgb_params['predictor'] = 'gpu_predictor'\n",
    "       \n",
    "        models = {\n",
    "            'xgb': xgb.XGBRegressor(**param),\n",
    "            'lgbm': lgbm.LGBMRegressor(),\n",
    "            'cat': cat.CatBoostRegressor(verbose=-1)\n",
    "            #add some models with default params to \"simplify\" ensemble\n",
    "            #'svc': SVC(random_state=self.random_state, probability=True),\n",
    "            #'brf': BalancedRandomForestClassifier(random_state=self.random_state),\n",
    "            #'lr': LogisticRegression(random_state=self.random_state)\n",
    "        }\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import partial\n",
    "import optuna\n",
    "\n",
    "class OptunaWeights:\n",
    "    def __init__(self, random_state, n_trials=1000):\n",
    "        self.study = None\n",
    "        self.weights = None\n",
    "        self.random_state = random_state\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial, y_true, y_preds):\n",
    "        # Define the weights for the predictions from each model\n",
    "        weights = [trial.suggest_float(f\"weight{n}\", 1e-14, 1) for n in range(len(y_preds))]\n",
    "\n",
    "        # Calculate the weighted prediction\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n",
    "\n",
    "        # Calculate the score for the weighted prediction\n",
    "        # score = log_loss(y_true, weighted_pred)\n",
    "        score = mean_squared_error(y_true, weighted_pred)\n",
    "        return score\n",
    "\n",
    "    def fit(self, y_true, y_preds):\n",
    "        optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='minimize')\n",
    "        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n",
    "        self.study.optimize(objective_partial, n_trials=self.n_trials)\n",
    "        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n",
    "\n",
    "    def predict(self, y_preds):\n",
    "        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n",
    "        return weighted_pred\n",
    "\n",
    "    def fit_predict(self, y_true, y_preds):\n",
    "        self.fit(y_true, y_preds)\n",
    "        return self.predict(y_preds)\n",
    "    \n",
    "    def weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xgb', 'cat', 'lgbm'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models = {'xgb':[], 'cat':[], 'lgbm':[]}\n",
    "\n",
    "trained_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-1824] MSE score: 0.23793\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-1824] MSE score: 0.23761\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-1824] MSE score: 0.22380\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-1824] MSE score: 0.21666\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-1824] MSE score: 0.20925\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-1824] MSE score: 0.18692\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-1824] MSE score: 0.22993\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-1824] MSE score: 0.21895\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-1824] MSE score: 0.19961\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-1824] MSE score: 0.21769\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-1824] MSE score: 0.21173\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-1824] MSE score: 0.18964\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-1824] MSE score: 0.22462\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-1824] MSE score: 0.21850\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-1824] MSE score: 0.19439\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-409] MSE score: 0.20056\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-409] MSE score: 0.19470\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-409] MSE score: 0.17390\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-409] MSE score: 0.23562\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-409] MSE score: 0.23343\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-409] MSE score: 0.21173\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-409] MSE score: 0.22881\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-409] MSE score: 0.21931\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-409] MSE score: 0.20465\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-409] MSE score: 0.23081\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-409] MSE score: 0.22295\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-409] MSE score: 0.19942\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-409] MSE score: 0.22942\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-409] MSE score: 0.21809\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-409] MSE score: 0.19888\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-4506] MSE score: 0.22762\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-4506] MSE score: 0.21572\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-4506] MSE score: 0.19422\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-4506] MSE score: 0.20970\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-4506] MSE score: 0.19797\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-4506] MSE score: 0.18274\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-4506] MSE score: 0.22367\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-4506] MSE score: 0.21831\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-4506] MSE score: 0.19638\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-4506] MSE score: 0.23838\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-4506] MSE score: 0.23514\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-4506] MSE score: 0.22132\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-4506] MSE score: 0.22563\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-4506] MSE score: 0.22039\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-4506] MSE score: 0.19979\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-4012] MSE score: 0.22717\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-4012] MSE score: 0.22207\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-4012] MSE score: 0.20209\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-4012] MSE score: 0.24960\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 99 iterations\n",
      "lgbm [FOLD-1 SEED-4012] MSE score: 0.23860\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-4012] MSE score: 0.21252\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-4012] MSE score: 0.23881\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-4012] MSE score: 0.22867\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-4012] MSE score: 0.20527\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-4012] MSE score: 0.23335\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-4012] MSE score: 0.23277\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-4012] MSE score: 0.20695\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-4012] MSE score: 0.20043\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-4012] MSE score: 0.18864\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-4012] MSE score: 0.16937\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-3657] MSE score: 0.24186\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-3657] MSE score: 0.23968\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-3657] MSE score: 0.21903\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-3657] MSE score: 0.23549\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-3657] MSE score: 0.22670\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-3657] MSE score: 0.20221\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-3657] MSE score: 0.21868\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-3657] MSE score: 0.21451\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-3657] MSE score: 0.19335\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-3657] MSE score: 0.20922\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-3657] MSE score: 0.20834\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-3657] MSE score: 0.18467\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-3657] MSE score: 0.22124\n",
      "--------------------------------------------------\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-3657] MSE score: 0.21177\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-3657] MSE score: 0.18905\n",
      "--------------------------------------------------\n",
      "CPU times: user 8min 25s, sys: 39.4 s, total: 9min 4s\n",
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from catboost import Pool\n",
    "import gc\n",
    "\n",
    "kfold = 'skf'\n",
    "n_splits = 5\n",
    "n_reapts = 5\n",
    "random_state = 42\n",
    "n_estimators = 99999\n",
    "early_stopping_rounds = 99\n",
    "verbose = False\n",
    "device = 'cpu'\n",
    "# Fix seed\n",
    "random.seed(random_state)\n",
    "random_state_list = random.sample(range(9999), n_reapts)\n",
    "#random_state_list = [42]\n",
    "\n",
    "# Initialize an array for storing test predictions\n",
    "classifier = Classifier(n_estimators, device, random_state)\n",
    "test_predss = np.zeros((testX.shape[0]))\n",
    "oof_predss = np.zeros((trainX.shape[0], n_reapts))\n",
    "ensemble_score, ensemble_score_ = [], []\n",
    "weights = []\n",
    "oof_each_predss = []\n",
    "oof_each_preds = np.zeros((trainX.shape[0], classifier.len_models))\n",
    "\n",
    "test_each_predss = []\n",
    "test_each_preds = np.zeros((testX.shape[0], classifier.len_models))\n",
    "\n",
    "trained_models = {'xgb':[], 'cat':[], 'lgbm':[]}\n",
    "score_dict = dict(zip(classifier.models_name, [[] for _ in range(classifier.len_models)]))\n",
    "\n",
    "splitter = Splitter(kfold=kfold, n_splits=n_splits)\n",
    "\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(trainX.reset_index(drop=True), trainy.reset_index(drop=True), random_state_list=random_state_list)):\n",
    "    n = i % n_splits\n",
    "    m = i // n_splits\n",
    "            \n",
    "    # Get a set of classifier models\n",
    "    classifier = Classifier(n_estimators, device, random_state_list[m])\n",
    "    models = classifier.models\n",
    "    \n",
    "    # Initialize lists to store oof and test predictions for each base model\n",
    "    oof_preds = []\n",
    "    test_preds = []\n",
    "    \n",
    "    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n",
    "    for name, model in models.items():\n",
    "        if ('xgb' in name) or ('lgbm' in name) or ('cat' in name):\n",
    "            #train_w0, train_w1 = calc_log_loss_weight(y_train_)\n",
    "            #valid_w0, valid_w1 = calc_log_loss_weight(y_val)\n",
    "            if 'xgb' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            elif 'lgbm' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            elif 'cat' in name:\n",
    "                model.fit(\n",
    "                    Pool(X_train_, y_train_), \n",
    "                    eval_set=Pool(X_val, y_val), \n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            \n",
    "        else:\n",
    "            model.fit(X_train_, y_train_)\n",
    "          \n",
    "        if name in trained_models.keys():\n",
    "            trained_models[f'{name}'].append(deepcopy(model))\n",
    "        \n",
    "        test_pred = model.predict(testX)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate recall and precision scores\n",
    "        mse = mean_squared_error(y_val, y_val_pred)\n",
    "        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] MSE score: {mse:.5f}')\n",
    "        print('-'*50)\n",
    "        #score = balanced_log_loss(y_val, y_val_pred)\n",
    "        #score_dict[name].append(score)\n",
    "        #print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] BalancedLogLoss score: {score:.5f}')\n",
    "        #print('-'*50)\n",
    "        \n",
    "        oof_preds.append(y_val_pred)\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    # Use Optuna to find the best ensemble weights\n",
    "    optweights = OptunaWeights(random_state=random_state_list[m])\n",
    "    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n",
    "    \n",
    "    #score = balanced_log_loss(y_val, y_val_pred)\n",
    "    #score_ = roc_auc_score(y_val, y_val_pred)\n",
    "    #print(f'--> Ensemble [FOLD-{n} SEED-{random_state_list[m]}] BalancedLogLoss score {score:.5f}')\n",
    "    #print('='*50)\n",
    "    #ensemble_score.append(score)\n",
    "    #ensemble_score_.append(score_)\n",
    "    weights.append(optweights.weights)\n",
    "    \n",
    "    # Predict to X_test by the best ensemble weights\n",
    "    test_predss += optweights.predict(test_preds) / (n_splits * len(random_state_list))\n",
    "    \n",
    "    oof_predss[X_val.index, m] += optweights.predict(oof_preds)\n",
    "    \n",
    "    oof_each_preds[X_val.index] = np.stack(oof_preds).T\n",
    "    test_each_preds += np.array(test_preds).T / n_splits\n",
    "    \n",
    "    if n == (n_splits - 1):\n",
    "        oof_each_predss.append(oof_each_preds)\n",
    "        oof_each_preds = np.zeros((trainX.shape[0], classifier.len_models))\n",
    "        test_each_predss.append(test_each_preds)\n",
    "        test_each_preds = np.zeros((testX.shape[0], classifier.len_models))\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "oof_each_predss = np.mean(np.array(oof_each_predss), axis=0)\n",
    "test_each_predss = np.mean(np.array(test_each_predss), axis=0)\n",
    "oof_each_predss = np.concatenate([oof_each_predss, np.mean(oof_predss, axis=1).reshape(-1, 1)], axis=1)\n",
    "test_each_predss = np.concatenate([test_each_predss, test_predss.reshape(-1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17544, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optuna Weights---\n",
      "xgb: 0.15833 ± 0.07208\n",
      "lgbm: 0.04257 ± 0.05067\n",
      "cat: 0.78652 ± 0.10304\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean score of the ensemble\n",
    "#mean_score = np.mean(ensemble_score)\n",
    "#std_score = np.std(ensemble_score)\n",
    "#print(f'Mean Optuna Ensemble {mean_score:.5f} ± {std_score:.5f} \\n')\n",
    "\n",
    "print('--- Optuna Weights---')\n",
    "mean_weights = np.mean(weights, axis=0)\n",
    "std_weights = np.std(weights, axis=0)\n",
    "for name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n",
    "    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Weights ---\n",
      "xgb: 0.15833 ± 0.07208\n",
      "lgbm: 0.04257 ± 0.05067\n",
      "cat: 0.78652 ± 0.10304\n",
      "\n",
      "CPU times: user 4min 1s, sys: 7.1 s, total: 4min 9s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stack_test_predss = np.zeros((testX.shape[0]))\n",
    "stack_scores = []\n",
    "stack_models = []\n",
    "splitter = Splitter(kfold=kfold, n_splits=n_splits)\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(oof_each_predss, trainy.reset_index(drop=True), random_state_list=random_state_list)):\n",
    "    n = i % n_splits\n",
    "    m = i // n_splits\n",
    "    classifier = Classifier(n_estimators, device, random_state_list[m])\n",
    "    models = classifier.models\n",
    "    model = models['xgb']\n",
    "    model.fit(X_train_, y_train_, \n",
    "    eval_set=[(X_val, y_val)], \n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose=verbose)\n",
    "    \n",
    "    #train_w0, train_w1 = calc_log_loss_weight(y_train_)\n",
    "    #valid_w0, valid_w1 = calc_log_loss_weight(y_val)\n",
    "    '''\n",
    "    if 'xgb' in one_model:\n",
    "        model.fit(\n",
    "        X_train_, y_train_, sample_weight=y_train_.map({0: train_w0, 1: train_w1}),\n",
    "        eval_set=[(X_val, y_val)],\n",
    "       # eval_metric='logloss',\n",
    "        sample_weight_eval_set=[y_val.map({0: valid_w0, 1: valid_w1})],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose=verbose)\n",
    "    elif 'tab' in one_model:\n",
    "        model.fit(X_train_, y_train_, overwrite_warning =True)\n",
    "    '''\n",
    "    #model.fit(X_train_, y_train_, overwrite_warning =True)\n",
    "    \n",
    "    test_pred = model.predict(test_each_predss)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    #score = balanced_log_loss(y_val, y_val_pred)\n",
    "    #stack_scores.append(score)\n",
    "    #stack_models.append(deepcopy(model))\n",
    "    \n",
    "    stack_test_predss += test_pred / (n_splits * len(random_state_list))\n",
    "\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "#mean_score = np.mean(ensemble_score)\n",
    "#std_score = np.std(ensemble_score)\n",
    "#print(f'Ensemble BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}')\n",
    "# Print the mean and standard deviation of the ensemble weights for each model\n",
    "print('--- Model Weights ---')\n",
    "mean_weights = np.mean(weights, axis=0)\n",
    "std_weights = np.std(weights, axis=0)\n",
    "for name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n",
    "    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')\n",
    "print('')\n",
    "\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "#mean_score = np.mean(stack_scores)\n",
    "#std_score = np.std(stack_scores)\n",
    "#print(f'Stacking BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57150565, 0.86836469, 4.92260692, ..., 1.89486144, 1.99892141,\n",
       "       1.51265009])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test_predss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1942095818325349"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pd.Series(testy), stack_test_predss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predy</th>\n",
       "      <th>testy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.571506</td>\n",
       "      <td>0.47700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.868365</td>\n",
       "      <td>0.45800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>4.922607</td>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>2.414125</td>\n",
       "      <td>2.18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>2.413817</td>\n",
       "      <td>2.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>1.616256</td>\n",
       "      <td>1.58700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>2.238780</td>\n",
       "      <td>1.98200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>1.612635</td>\n",
       "      <td>1.57500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2.967142</td>\n",
       "      <td>3.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>4.865237</td>\n",
       "      <td>4.46600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>1.042330</td>\n",
       "      <td>1.23200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>2.116781</td>\n",
       "      <td>2.53900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>1.617408</td>\n",
       "      <td>2.15100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20267</th>\n",
       "      <td>1.818446</td>\n",
       "      <td>2.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>2.361480</td>\n",
       "      <td>2.19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>1.647071</td>\n",
       "      <td>1.36200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1.955918</td>\n",
       "      <td>1.78400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>1.643558</td>\n",
       "      <td>1.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14173</th>\n",
       "      <td>1.395555</td>\n",
       "      <td>1.39800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>0.965242</td>\n",
       "      <td>1.37500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predy    testy\n",
       "20046  0.571506  0.47700\n",
       "3024   0.868365  0.45800\n",
       "15663  4.922607  5.00001\n",
       "20484  2.414125  2.18600\n",
       "9814   2.413817  2.78000\n",
       "13311  1.616256  1.58700\n",
       "7113   2.238780  1.98200\n",
       "7668   1.612635  1.57500\n",
       "18246  2.967142  3.40000\n",
       "5723   4.865237  4.46600\n",
       "20069  1.042330  1.23200\n",
       "6835   2.116781  2.53900\n",
       "11351  1.617408  2.15100\n",
       "20267  1.818446  2.20500\n",
       "7097   2.361480  2.19800\n",
       "6298   1.647071  1.36200\n",
       "696    1.955918  1.78400\n",
       "19607  1.643558  1.87500\n",
       "14173  1.395555  1.39800\n",
       "19638  0.965242  1.37500"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'predy':stack_test_predss, 'testy':pd.Series(testy)}).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19404162894645924"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pd.Series(testy), stack_test_predss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predy</th>\n",
       "      <th>testy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.981289</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.345647</td>\n",
       "      <td>2.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.626399</td>\n",
       "      <td>1.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.236008</td>\n",
       "      <td>1.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.858446</td>\n",
       "      <td>1.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.369074</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.657917</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.255657</td>\n",
       "      <td>1.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.720502</td>\n",
       "      <td>1.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.785316</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.137778</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.963779</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.499328</td>\n",
       "      <td>1.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2.516037</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.304705</td>\n",
       "      <td>2.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3.321949</td>\n",
       "      <td>3.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3.249338</td>\n",
       "      <td>2.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3.871545</td>\n",
       "      <td>3.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4.111285</td>\n",
       "      <td>3.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>4.304749</td>\n",
       "      <td>3.659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predy  testy\n",
       "3    2.981289  3.413\n",
       "6    2.345647  2.992\n",
       "17   1.626399  1.555\n",
       "31   1.236008  1.152\n",
       "34   1.858446  1.097\n",
       "35   1.369074  0.972\n",
       "41   1.657917  1.500\n",
       "42   1.255657  1.188\n",
       "46   1.720502  1.425\n",
       "57   0.785316  0.853\n",
       "59   2.137778  0.600\n",
       "88   1.963779  1.375\n",
       "90   1.499328  1.625\n",
       "103  2.516037  3.500\n",
       "115  2.304705  2.316\n",
       "119  3.321949  3.476\n",
       "127  3.249338  2.923\n",
       "133  3.871545  3.333\n",
       "134  4.111285  3.352\n",
       "137  4.304749  3.659"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'predy':stack_test_predss, 'testy':pd.Series(testy)}).sort_index().head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
