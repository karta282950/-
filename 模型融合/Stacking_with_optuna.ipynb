{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_california_housing(as_frame=True)[\"frame\"]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(df.drop(columns=['MedHouseVal']), df.MedHouseVal, test_size=0.15, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "class Splitter:\n",
    "    def __init__(self, kfold=True, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.kfold = kfold\n",
    "\n",
    "    def split_data(self, X, y, random_state_list):\n",
    "        if self.kfold == 'skf':\n",
    "            for random_state in random_state_list:\n",
    "                kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n",
    "                for train_index, val_index in kf.split(X, y):\n",
    "                    if type(X) is np.ndarray:\n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "                    else:\n",
    "                        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                    yield X_train, X_val, y_train, y_val\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid kfold: Must be True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, n_estimators=100, device=\"cpu\", random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.device = device\n",
    "        self.random_state = random_state\n",
    "        self.models = self._define_model()\n",
    "        self.models_name = list(self._define_model().keys())\n",
    "        self.len_models = len(self.models)\n",
    "        \n",
    "    def _define_model(self):\n",
    "        xgb_params = {}\n",
    "        #param = {'n_estimators': 850, 'max_depth': 7, 'learning_rate': 0.035579334505517195, \n",
    "        # 'subsample': 0.7433060185168757, 'colsample_bytree': 0.9985782631581257, 'gamma': 0.014679853880810986}\n",
    "        param_xgb = {'n_estimators': 950, 'max_depth': 7, 'learning_rate': 0.053205633034397806, 'subsample': 0.9270682514998716, 'colsample_bytree': 0.7921756371948105, 'gamma': 0.014086740287365148}\n",
    "        param_lgbm = {'lambda_l1': 4.12348857087004e-06, 'lambda_l2': 0.005500580751154387, 'num_leaves': 100, 'learning_rate': 0.09706783767482643, 'feature_fraction': 0.7069249789707748, 'bagging_fraction': 0.8329693941192573, 'bagging_freq': 6, 'min_child_samples': 25, 'num_threads': 7}\n",
    "        param_cat = {'iterations': 11907, 'od_wait': 1936, 'learning_rate': 0.1899099511160147, 'reg_lambda': 67.66690655367276, 'subsample': 0.9376510157656168, 'random_strength': 20.855157436589423, 'depth': 7, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 2}\n",
    "        if self.device == 'gpu':\n",
    "            xgb_params['tree_method'] = 'gpu_hist'\n",
    "            xgb_params['predictor'] = 'gpu_predictor'\n",
    "       \n",
    "        models = {\n",
    "            'xgb': xgb.XGBRegressor(**param_xgb),\n",
    "            'lgbm': lgbm.LGBMRegressor(**param_lgbm),\n",
    "            'cat': cat.CatBoostRegressor(**param_cat)\n",
    "            #add some models with default params to \"simplify\" ensemble\n",
    "            #'svc': SVC(random_state=self.random_state, probability=True),\n",
    "            #'brf': BalancedRandomForestClassifier(random_state=self.random_state),\n",
    "            #'lr': LogisticRegression(random_state=self.random_state)\n",
    "        }\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import partial\n",
    "import optuna\n",
    "\n",
    "class OptunaWeights:\n",
    "    def __init__(self, random_state, n_trials=1000):\n",
    "        self.study = None\n",
    "        self.weights = None\n",
    "        self.random_state = random_state\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial, y_true, y_preds):\n",
    "        # Define the weights for the predictions from each model\n",
    "        weights = [trial.suggest_float(f\"weight{n}\", 1e-14, 1) for n in range(len(y_preds))]\n",
    "\n",
    "        # Calculate the weighted prediction\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n",
    "\n",
    "        # Calculate the score for the weighted prediction\n",
    "        # score = log_loss(y_true, weighted_pred)\n",
    "        score = mean_squared_error(y_true, weighted_pred)\n",
    "        return score\n",
    "\n",
    "    def fit(self, y_true, y_preds):\n",
    "        optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='minimize')\n",
    "        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n",
    "        self.study.optimize(objective_partial, n_trials=self.n_trials)\n",
    "        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n",
    "\n",
    "    def predict(self, y_preds):\n",
    "        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n",
    "        return weighted_pred\n",
    "\n",
    "    def fit_predict(self, y_true, y_preds):\n",
    "        self.fit(y_true, y_preds)\n",
    "        return self.predict(y_preds)\n",
    "    \n",
    "    def weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-1824] MSE score: 0.21507\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 93 iterations\n",
      "lgbm [FOLD-0 SEED-1824] MSE score: 0.21789\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-1824] MSE score: 0.22097\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-0 SEED-1824] MSE 0.20921\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-1824] MSE score: 0.19359\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 97 iterations\n",
      "lgbm [FOLD-1 SEED-1824] MSE score: 0.18580\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-1824] MSE score: 0.18094\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-1 SEED-1824] MSE 0.17488\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-1824] MSE score: 0.20329\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-1824] MSE score: 0.20269\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-1824] MSE score: 0.19950\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-2 SEED-1824] MSE 0.19288\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-1824] MSE score: 0.19091\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 90 iterations\n",
      "lgbm [FOLD-3 SEED-1824] MSE score: 0.19008\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-1824] MSE score: 0.17997\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-3 SEED-1824] MSE 0.17554\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-1824] MSE score: 0.19142\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-1824] MSE score: 0.19592\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-1824] MSE score: 0.18777\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-4 SEED-1824] MSE 0.18138\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-409] MSE score: 0.17439\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 99 iterations\n",
      "lgbm [FOLD-0 SEED-409] MSE score: 0.17401\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-409] MSE score: 0.16889\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-0 SEED-409] MSE 0.16230\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-409] MSE score: 0.21173\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 98 iterations\n",
      "lgbm [FOLD-1 SEED-409] MSE score: 0.20993\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-409] MSE score: 0.20271\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-1 SEED-409] MSE 0.19774\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-409] MSE score: 0.19784\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 99 iterations\n",
      "lgbm [FOLD-2 SEED-409] MSE score: 0.20425\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-409] MSE score: 0.19910\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-2 SEED-409] MSE 0.19124\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-409] MSE score: 0.20094\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-409] MSE score: 0.20279\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-409] MSE score: 0.19498\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-3 SEED-409] MSE 0.18931\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-409] MSE score: 0.20126\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-409] MSE score: 0.20637\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-409] MSE score: 0.19755\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-4 SEED-409] MSE 0.19241\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-4506] MSE score: 0.19641\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-4506] MSE score: 0.19575\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-4506] MSE score: 0.19044\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-0 SEED-4506] MSE 0.18408\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-4506] MSE score: 0.17430\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 97 iterations\n",
      "lgbm [FOLD-1 SEED-4506] MSE score: 0.18363\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-4506] MSE score: 0.17603\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-1 SEED-4506] MSE 0.16761\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-4506] MSE score: 0.19740\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-4506] MSE score: 0.19461\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-4506] MSE score: 0.19041\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-2 SEED-4506] MSE 0.18448\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-4506] MSE score: 0.21252\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-3 SEED-4506] MSE score: 0.21703\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-4506] MSE score: 0.21455\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-3 SEED-4506] MSE 0.20570\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-4506] MSE score: 0.19708\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-4506] MSE score: 0.20568\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-4506] MSE score: 0.19540\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-4 SEED-4506] MSE 0.18870\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-4012] MSE score: 0.19585\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 84 iterations\n",
      "lgbm [FOLD-0 SEED-4012] MSE score: 0.20371\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-4012] MSE score: 0.19153\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-0 SEED-4012] MSE 0.18629\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-4012] MSE score: 0.21527\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-4012] MSE score: 0.21718\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-4012] MSE score: 0.21131\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-1 SEED-4012] MSE 0.20482\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-4012] MSE score: 0.20866\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-4012] MSE score: 0.20550\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-4012] MSE score: 0.20400\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-2 SEED-4012] MSE 0.19668\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-4012] MSE score: 0.20562\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 97 iterations\n",
      "lgbm [FOLD-3 SEED-4012] MSE score: 0.21229\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-4012] MSE score: 0.20696\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-3 SEED-4012] MSE 0.19839\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-4012] MSE score: 0.17161\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-4 SEED-4012] MSE score: 0.17185\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-4012] MSE score: 0.16929\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-4 SEED-4012] MSE 0.16176\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-0 SEED-3657] MSE score: 0.21840\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-0 SEED-3657] MSE score: 0.22470\n",
      "--------------------------------------------------\n",
      "cat [FOLD-0 SEED-3657] MSE score: 0.21350\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-0 SEED-3657] MSE 0.20805\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-1 SEED-3657] MSE score: 0.20477\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-1 SEED-3657] MSE score: 0.20783\n",
      "--------------------------------------------------\n",
      "cat [FOLD-1 SEED-3657] MSE score: 0.20194\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-1 SEED-3657] MSE 0.19459\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-2 SEED-3657] MSE score: 0.19094\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 100 iterations\n",
      "lgbm [FOLD-2 SEED-3657] MSE score: 0.19247\n",
      "--------------------------------------------------\n",
      "cat [FOLD-2 SEED-3657] MSE score: 0.18767\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-2 SEED-3657] MSE 0.18062\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-3 SEED-3657] MSE score: 0.18507\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 94 iterations\n",
      "lgbm [FOLD-3 SEED-3657] MSE score: 0.19244\n",
      "--------------------------------------------------\n",
      "cat [FOLD-3 SEED-3657] MSE score: 0.17741\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-3 SEED-3657] MSE 0.17319\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukaisun/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb [FOLD-4 SEED-3657] MSE score: 0.18606\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] num_threads is set=7, n_jobs=-1 will be ignored. Current value: num_threads=7\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.12348857087004e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.12348857087004e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069249789707748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069249789707748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8329693941192573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8329693941192573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005500580751154387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005500580751154387\n",
      "Finished loading model, total used 90 iterations\n",
      "lgbm [FOLD-4 SEED-3657] MSE score: 0.19474\n",
      "--------------------------------------------------\n",
      "cat [FOLD-4 SEED-3657] MSE score: 0.18896\n",
      "--------------------------------------------------\n",
      "--> Ensemble [FOLD-4 SEED-3657] MSE 0.17993\n",
      "==================================================\n",
      "CPU times: user 29min 44s, sys: 2min 22s, total: 32min 6s\n",
      "Wall time: 13min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from catboost import Pool\n",
    "import gc\n",
    "\n",
    "kfold = 'skf'\n",
    "n_splits = 5\n",
    "n_reapts = 5\n",
    "random_state = 42\n",
    "n_estimators = 99999\n",
    "early_stopping_rounds = 99\n",
    "verbose = False\n",
    "device = 'cpu'\n",
    "# Fix seed\n",
    "random.seed(random_state)\n",
    "random_state_list = random.sample(range(9999), n_reapts)\n",
    "#random_state_list = [42]\n",
    "\n",
    "# Initialize an array for storing test predictions\n",
    "classifier = Classifier(n_estimators, device, random_state)\n",
    "test_predss = np.zeros((testX.shape[0]))\n",
    "oof_predss = np.zeros((trainX.shape[0], n_reapts))\n",
    "ensemble_score, ensemble_score_ = [], []\n",
    "weights = []\n",
    "oof_each_predss = []\n",
    "oof_each_preds = np.zeros((trainX.shape[0], classifier.len_models))\n",
    "\n",
    "test_each_predss = []\n",
    "test_each_preds = np.zeros((testX.shape[0], classifier.len_models))\n",
    "\n",
    "trained_models = {'xgb':[], 'cat':[], 'lgbm':[]}\n",
    "score_dict = dict(zip(classifier.models_name, [[] for _ in range(classifier.len_models)]))\n",
    "\n",
    "splitter = Splitter(kfold=kfold, n_splits=n_splits)\n",
    "\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(trainX.reset_index(drop=True), trainy.reset_index(drop=True), random_state_list=random_state_list)):\n",
    "    n = i % n_splits\n",
    "    m = i // n_splits\n",
    "            \n",
    "    # Get a set of classifier models\n",
    "    classifier = Classifier(n_estimators, device, random_state_list[m])\n",
    "    models = classifier.models\n",
    "    \n",
    "    # Initialize lists to store oof and test predictions for each base model\n",
    "    oof_preds = []\n",
    "    test_preds = []\n",
    "    \n",
    "    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n",
    "    for name, model in models.items():\n",
    "        if ('xgb' in name) or ('lgbm' in name) or ('cat' in name):\n",
    "            '''\n",
    "            分類任務計算類別比例\n",
    "            train_w0, train_w1 = calc_log_loss_weight(y_train_)\n",
    "            valid_w0, valid_w1 = calc_log_loss_weight(y_val)\n",
    "            '''\n",
    "            if 'xgb' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            elif 'lgbm' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            elif 'cat' in name:\n",
    "                model.fit(\n",
    "                    Pool(X_train_, y_train_), \n",
    "                    eval_set=Pool(X_val, y_val), \n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "            \n",
    "        else:\n",
    "            model.fit(X_train_, y_train_)\n",
    "          \n",
    "        if name in trained_models.keys():\n",
    "            trained_models[f'{name}'].append(deepcopy(model))\n",
    "        \n",
    "        test_pred = model.predict(testX)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate recall and precision scores\n",
    "        mse = mean_squared_error(y_val, y_val_pred)\n",
    "        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] MSE score: {mse:.5f}')\n",
    "        print('-'*50)\n",
    "        score_dict[name].append(mse)\n",
    "        #score = balanced_log_loss(y_val, y_val_pred)\n",
    "        #score_dict[name].append(score)\n",
    "        #print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] BalancedLogLoss score: {score:.5f}')\n",
    "        #print('-'*50)\n",
    "        \n",
    "        oof_preds.append(y_val_pred)\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    # Use Optuna to find the best ensemble weights\n",
    "    optweights = OptunaWeights(random_state=random_state_list[m])\n",
    "    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n",
    "    \n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "    print(f'--> Ensemble [FOLD-{n} SEED-{random_state_list[m]}] MSE {mse:.5f}')\n",
    "    print('='*50)\n",
    "    ensemble_score.append(mse)\n",
    "    #score = balanced_log_loss(y_val, y_val_pred)\n",
    "    #score_ = roc_auc_score(y_val, y_val_pred)\n",
    "    #print(f'--> Ensemble [FOLD-{n} SEED-{random_state_list[m]}] BalancedLogLoss score {score:.5f}')\n",
    "    #print('='*50)\n",
    "    #ensemble_score.append(score)\n",
    "    #ensemble_score_.append(score_)\n",
    "    weights.append(optweights.weights)\n",
    "    \n",
    "    # Predict to X_test by the best ensemble weights\n",
    "    test_predss += optweights.predict(test_preds) / (n_splits * len(random_state_list))\n",
    "    \n",
    "    oof_predss[X_val.index, m] += optweights.predict(oof_preds)\n",
    "    \n",
    "    oof_each_preds[X_val.index] = np.stack(oof_preds).T\n",
    "    test_each_preds += np.array(test_preds).T / n_splits\n",
    "    \n",
    "    if n == (n_splits - 1):\n",
    "        oof_each_predss.append(oof_each_preds)\n",
    "        oof_each_preds = np.zeros((trainX.shape[0], classifier.len_models))\n",
    "        test_each_predss.append(test_each_preds)\n",
    "        test_each_preds = np.zeros((testX.shape[0], classifier.len_models))\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "oof_each_predss = np.mean(np.array(oof_each_predss), axis=0)\n",
    "test_each_predss = np.mean(np.array(test_each_predss), axis=0)\n",
    "oof_each_predss = np.concatenate([oof_each_predss, np.mean(oof_predss, axis=1).reshape(-1, 1)], axis=1)\n",
    "test_each_predss = np.concatenate([test_each_predss, test_predss.reshape(-1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optuna Weights---\n",
      "xgb: 0.47545 ± 0.19207\n",
      "lgbm: 0.37258 ± 0.17071\n",
      "cat: 0.73036 ± 0.11893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n--- Optuna Weights---\\nxgb: 0.15833 ± 0.07208\\nlgbm: 0.04257 ± 0.05067\\ncat: 0.78652 ± 0.10304\\n--- Optuna Weights---\\nxgb: 0.74496 ± 0.13414\\nlgbm: 0.00073 ± 0.00357\\ncat: 0.66206 ± 0.17437\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean score of the ensemble\n",
    "#mean_score = np.mean(ensemble_score)\n",
    "#std_score = np.std(ensemble_score)\n",
    "#print(f'Mean Optuna Ensemble {mean_score:.5f} ± {std_score:.5f} \\n')\n",
    "\n",
    "print('--- Optuna Weights---')\n",
    "mean_weights = np.mean(weights, axis=0)\n",
    "std_weights = np.std(weights, axis=0)\n",
    "for name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n",
    "    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')\n",
    "'''\n",
    "--- Optuna Weights---\n",
    "xgb: 0.15833 ± 0.07208\n",
    "lgbm: 0.04257 ± 0.05067\n",
    "cat: 0.78652 ± 0.10304\n",
    "--- Optuna Weights---\n",
    "xgb: 0.74496 ± 0.13414\n",
    "lgbm: 0.00073 ± 0.00357\n",
    "cat: 0.66206 ± 0.17437\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Weights ---\n",
      "xgb: 0.47545 ± 0.19207\n",
      "lgbm: 0.37258 ± 0.17071\n",
      "cat: 0.73036 ± 0.11893\n",
      "\n",
      "CPU times: user 3min 40s, sys: 1.92 s, total: 3min 42s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n--- Model Weights ---\\nxgb: 0.15833 ± 0.07208\\nlgbm: 0.04257 ± 0.05067\\ncat: 0.78652 ± 0.10304\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stack_test_predss = np.zeros((testX.shape[0]))\n",
    "stack_scores = []\n",
    "stack_models = []\n",
    "splitter = Splitter(kfold=kfold, n_splits=n_splits)\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(oof_each_predss, trainy.reset_index(drop=True), random_state_list=random_state_list)):\n",
    "    n = i % n_splits\n",
    "    m = i // n_splits\n",
    "    classifier = Classifier(n_estimators, device, random_state_list[m])\n",
    "    models = classifier.models\n",
    "    model = models['xgb']\n",
    "    model.fit(X_train_, y_train_, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              early_stopping_rounds=early_stopping_rounds,\n",
    "              verbose=verbose)\n",
    "    \n",
    "    #train_w0, train_w1 = calc_log_loss_weight(y_train_)\n",
    "    #valid_w0, valid_w1 = calc_log_loss_weight(y_val)\n",
    "    '''\n",
    "    if 'xgb' in one_model:\n",
    "        model.fit(\n",
    "        X_train_, y_train_, sample_weight=y_train_.map({0: train_w0, 1: train_w1}),\n",
    "        eval_set=[(X_val, y_val)],\n",
    "       # eval_metric='logloss',\n",
    "        sample_weight_eval_set=[y_val.map({0: valid_w0, 1: valid_w1})],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose=verbose)\n",
    "    elif 'tab' in one_model:\n",
    "        model.fit(X_train_, y_train_, overwrite_warning =True)\n",
    "    '''\n",
    "    #model.fit(X_train_, y_train_, overwrite_warning =True)\n",
    "    \n",
    "    test_pred = model.predict(test_each_predss)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    #score = balanced_log_loss(y_val, y_val_pred)\n",
    "    #stack_scores.append(score)\n",
    "    #stack_models.append(deepcopy(model))\n",
    "    \n",
    "    stack_test_predss += test_pred / (n_splits * len(random_state_list))\n",
    "\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "#mean_score = np.mean(ensemble_score)\n",
    "#std_score = np.std(ensemble_score)\n",
    "#print(f'Ensemble BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}')\n",
    "# Print the mean and standard deviation of the ensemble weights for each model\n",
    "print('--- Model Weights ---')\n",
    "mean_weights = np.mean(weights, axis=0)\n",
    "std_weights = np.std(weights, axis=0)\n",
    "for name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n",
    "    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')\n",
    "print('')\n",
    "\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "#mean_score = np.mean(stack_scores)\n",
    "#std_score = np.std(stack_scores)\n",
    "#print(f'Stacking BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}\\n')\n",
    "'''\n",
    "--- Model Weights ---\n",
    "xgb: 0.15833 ± 0.07208\n",
    "lgbm: 0.04257 ± 0.05067\n",
    "cat: 0.78652 ± 0.10304\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18305954190528265"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pd.Series(testy), stack_test_predss)\n",
    "#0.1942095818325349\n",
    "#xgb: 0.18305954190528265\n",
    "#cat: 0.18361486683150585\n",
    "#lgbm: 0.1868822166265703\n",
    "#default: 0.19311667127279547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predy</th>\n",
       "      <th>testy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.555777</td>\n",
       "      <td>0.47700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.772075</td>\n",
       "      <td>0.45800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>4.931699</td>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>2.367049</td>\n",
       "      <td>2.18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>2.367405</td>\n",
       "      <td>2.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>1.571142</td>\n",
       "      <td>1.58700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>2.205099</td>\n",
       "      <td>1.98200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>1.554310</td>\n",
       "      <td>1.57500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>3.020706</td>\n",
       "      <td>3.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>4.927600</td>\n",
       "      <td>4.46600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>0.929289</td>\n",
       "      <td>1.23200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>2.161858</td>\n",
       "      <td>2.53900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>1.605358</td>\n",
       "      <td>2.15100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20267</th>\n",
       "      <td>1.692837</td>\n",
       "      <td>2.20500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>2.341356</td>\n",
       "      <td>2.19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>1.600952</td>\n",
       "      <td>1.36200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1.961729</td>\n",
       "      <td>1.78400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>1.548631</td>\n",
       "      <td>1.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14173</th>\n",
       "      <td>1.341992</td>\n",
       "      <td>1.39800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>0.920117</td>\n",
       "      <td>1.37500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predy    testy\n",
       "20046  0.555777  0.47700\n",
       "3024   0.772075  0.45800\n",
       "15663  4.931699  5.00001\n",
       "20484  2.367049  2.18600\n",
       "9814   2.367405  2.78000\n",
       "13311  1.571142  1.58700\n",
       "7113   2.205099  1.98200\n",
       "7668   1.554310  1.57500\n",
       "18246  3.020706  3.40000\n",
       "5723   4.927600  4.46600\n",
       "20069  0.929289  1.23200\n",
       "6835   2.161858  2.53900\n",
       "11351  1.605358  2.15100\n",
       "20267  1.692837  2.20500\n",
       "7097   2.341356  2.19800\n",
       "6298   1.600952  1.36200\n",
       "696    1.961729  1.78400\n",
       "19607  1.548631  1.87500\n",
       "14173  1.341992  1.39800\n",
       "19638  0.920117  1.37500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'predy':stack_test_predss, 'testy':pd.Series(testy)}).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
